# This is the configuration file
# for configuring how the form-generating feature of the crawler
# will generate form data to submit GET and POST forms

# Obviously, this configuration file is divided into 2 headers: [GET] and [POST]
# which will obviously be used to configure behavior for the two different form types

# Within each header, the following configuration options can be used:

# form_input_type = form_input value
# e.g:
# Password = whatever
# this will set the value of every <input type='password'> parameter value to 'whatever'

# You can also set many values to 'intelligence' (without quotes)
# this instructs the crawler to intelligently generate a value that is most likely to work,
# to submit the form using an intelligently-generated value,
# which it does by using a combination of html placeholder attribute values, the maxlength attribute, e.t.c
# as well as the actual HTML input type itself
# e.g a <input type='email'> tag will always cause the crawler to generate a string that looks like a valid email address
# and <input type='date'> will always cause the crawler to generate an actual date

# intelligence does not work on every input type
# the default configuration settings below use intelligence on every input type which allows it
# certain other inputs type (radio, checkbox) do not allow it

# for radios:
# 'random' means it selects one of the radio button options at random
# 'none' means it does not select any of them
# 'first' means it always select the first option, as it would be displayed in the web-browser
# 'last' means it always selects the last option

# for checkboxes:
# 'random' means each checkbox has a 50/50 chance of being selected, or not selected
# 'all' means each checkbox will always be checked
# 'none' means each checkbox will never be checked

# for 'select' statements
# i.e <select> </select> tags
# 'first' means it will always select the first option in the list, i.e the value of the first <option> tag
# 'last' is the same as the first, except with the last option in the list
# 'random' means it selects an option value at random
# and 'none' means it will not submit that form parameter at all

# there is also the 'Default' setting, e.g
# Default = intelligence
# this Default setting tells the crawler how to generate a value for input types that are not in the configuration file
# or are not supported

# with each input type that can be used with intelligence, you can also simply hard-write a value into it
# e.g:
# Textarea = Trails of Cold Steel is awesome!

# You can also use comma-separated lists
# e.g:
# Radio = first,last,none
# (unfortunately, this means you cannot use commas in the actual values themselves)

# If you do use a comma-separated list...
# each time the crawler submits a form, it will select 1 value from among the list and use that value as the parameter value
# (or in the case of "intelligence", it will generate the value intelligently)
# The way that the crawler will select from among the options, is determined by the "Method" settings
# e.g:
# Method = random
# Setting 'Method = random' means that each time the crawler submits a form, if it encounters an input type that is configured
# with a comma-separated list,
# it will select 1 value - at random - from among the options
# if you set 'Method' to anything else, e.g:
# Method = whatever
# The crawler will simply iterate through the list as it makes its submissions

# And lastly, the 'Submissions' settings tells the crawler how many times to submit each form
# e.g Submissions = 3
# will mean that, for each form it encounters, it will submit it 3 times
# and each time, if you use any randomly-generated settings or intelligently-generated settings,
# it may generate new form data for each form submission
# the purpose of submitting a form multiple times may be so that,
# if invalid form data is submitted 1 time, it may be resubmitted again differently,
# and you may be lucky enough that at least 1 form submission will be deemed valid,
# and the appropriate HTML will be sent back to the crawler,
# which it otherwise may have missed.

# Don't use more than 1 header of the same name. It will confuse the crawler.
# Make sure there is 1 - and only 1 - GET header,
# as well as 1 - and only 1 - POST header

# Do not use 'intelligence' as a hard-coded value, as this will actually instruct the crawler to generate a value intelligently,
# and the string 'intelligence' will not be what ends up being used

# do not use 'intelligence' on a checkbox, radio button, or select statement

# do not have any line typed in more than once, e.g
# Number = intelligence
# Number = intelligence

# Don't try anything funny, like entering a non-numerical digit, or a negative number for the 'Submissions' value

[GET]
Method = random
Submissions = 3
Textarea = intelligence
Text = intelligence
Password = intelligence
Email = intelligence
Color = intelligence
Date = intelligence
Datetime-local = intelligence
Hidden = intelligence
Month = intelligence
Number = intelligence
Range = intelligence
Search = intelligence
Tel = intelligence
Time = intelligence
Url = intelligence
Week = intelligence
Radio = random
Checkbox = random,all,none
Select = first,none,random
Default = intelligence

[POST]
Method = random
Submissions = 3
Textarea = intelligence
Text = intelligence
Password = intelligence
Email = intelligence
Color = intelligence
Date = intelligence
Datetime-local = intelligence
Hidden = intelligence
Month = intelligence
Number = intelligence
Range = intelligence
Search = intelligence
Tel = intelligence
Time = intelligence
Url = intelligence
Week = intelligence
Radio = random
Checkbox = random,all,none
Select = first,none,random
Default = intelligence
